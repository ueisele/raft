package raft_test

import (
	"context"
	"fmt"
	"sync"
	"testing"
	"time"
	
	"github.com/ueisele/raft"
	"github.com/ueisele/raft/test"
)

// TestPendingConfigChangeBlocking tests that pending config changes block new ones
func TestPendingConfigChangeBlocking(t *testing.T) {
	// Create 3-node cluster
	cluster := test.NewTestCluster(t, test.DefaultClusterConfig(3))
	defer cluster.Stop()
	
	ctx := context.Background()
	if err := cluster.Start(ctx); err != nil {
		t.Fatalf("Failed to start cluster: %v", err)
	}
		config := &Config{
			ID:                 i,
			Peers:              []int{0, 1, 2},
			ElectionTimeoutMin: 150 * time.Millisecond,
			ElectionTimeoutMax: 300 * time.Millisecond,
			HeartbeatInterval:  50 * time.Millisecond,
			Logger:             &testLogger{t: t},
		}

		transport := &debugTransport{
			id:       i,
			registry: registry,
			logger:   &testLogger{t: t},
		}

		stateMachine := &testStateMachine{
			mu:   sync.Mutex{},
			data: make(map[string]string),
		}

		node, err := NewNode(config, transport, nil, stateMachine)
		if err != nil {
			t.Fatalf("Failed to create node %d: %v", i, err)
		}

		nodes[i] = node
		registry.nodes[i] = node.(RPCHandler)
	}

	// Start all nodes
	ctx := context.Background()
	for i, node := range nodes {
		if err := node.Start(ctx); err != nil {
			t.Fatalf("Failed to start node %d: %v", i, err)
		}
		defer node.Stop()
	}

	// Wait for leader election
	time.Sleep(500 * time.Millisecond)

	// Find leader
	var leader Node
	for _, node := range nodes {
		if node.IsLeader() {
			leader = node
			break
		}
	}

	if leader == nil {
		t.Fatal("No leader elected")
	}

	// Start first config change
	err := leader.AddServer(3, "server-3:8003", true)
	if err != nil {
		t.Logf("First config change returned: %v", err)
	}

	// Immediately try second config change (should be blocked)
	err2 := leader.AddServer(4, "server-4:8004", true)
	if err2 == nil {
		t.Error("Second config change should have been blocked")
	} else {
		t.Logf("Second config change correctly blocked: %v", err2)
	}

	// Wait for first change to complete
	time.Sleep(1 * time.Second)

	// Now second change should succeed
	err3 := leader.AddServer(4, "server-4:8004", true)
	if err3 != nil {
		t.Logf("Third config change (after waiting) returned: %v", err3)
	}
}

// TestTwoNodeElectionDynamics tests election behavior in 2-node cluster
func TestTwoNodeElectionDynamics(t *testing.T) {
	// Create 2-node cluster
	nodes := make([]Node, 2)
	registry := &debugNodeRegistry{
		nodes:  make(map[int]RPCHandler),
		logger: &testLogger{t: t},
	}

	for i := 0; i < 2; i++ {
		config := &Config{
			ID:                 i,
			Peers:              []int{0, 1},
			ElectionTimeoutMin: 150 * time.Millisecond,
			ElectionTimeoutMax: 300 * time.Millisecond,
			HeartbeatInterval:  50 * time.Millisecond,
			Logger:             &testLogger{t: t},
		}

		transport := &debugTransport{
			id:       i,
			registry: registry,
			logger:   &testLogger{t: t},
		}

		stateMachine := &testStateMachine{
			mu:   sync.Mutex{},
			data: make(map[string]string),
		}

		node, err := NewNode(config, transport, nil, stateMachine)
		if err != nil {
			t.Fatalf("Failed to create node %d: %v", i, err)
		}

		nodes[i] = node
		registry.nodes[i] = node.(RPCHandler)
	}

	// Start both nodes
	ctx := context.Background()
	for i, node := range nodes {
		if err := node.Start(ctx); err != nil {
			t.Fatalf("Failed to start node %d: %v", i, err)
		}
		defer node.Stop()
	}

	// Wait for leader election
	time.Sleep(500 * time.Millisecond)

	// Verify exactly one leader
	leaderCount := 0
	var leaderID int
	for i, node := range nodes {
		if node.IsLeader() {
			leaderCount++
			leaderID = i
		}
	}

	if leaderCount != 1 {
		t.Errorf("Expected exactly 1 leader in 2-node cluster, found %d", leaderCount)
	} else {
		t.Logf("Leader elected: node %d", leaderID)
	}

	// Stop the follower
	followerID := 1 - leaderID
	nodes[followerID].Stop()
	t.Logf("Stopped follower node %d", followerID)

	// Leader should not be able to commit new entries (no quorum)
	initialCommit := nodes[leaderID].GetCommitIndex()

	_, _, isLeader := nodes[leaderID].Submit("test-command")
	if !isLeader {
		t.Error("Node should still think it's leader")
	}

	// Wait a bit
	time.Sleep(500 * time.Millisecond)

	// Commit index should not advance
	newCommit := nodes[leaderID].GetCommitIndex()
	if newCommit > initialCommit {
		t.Error("Leader committed without quorum in 2-node cluster")
	}

	t.Log("Verified: 2-node cluster requires both nodes for quorum")
}

// TestLeaderSnapshotDuringConfigChange tests snapshot creation during config change
func TestLeaderSnapshotDuringConfigChange(t *testing.T) {
	// Create 3-node cluster with small snapshot interval
	nodes := make([]Node, 3)
	registry := &debugNodeRegistry{
		nodes:  make(map[int]RPCHandler),
		logger: &testLogger{t: t},
	}

	for i := 0; i < 3; i++ {
		config := &Config{
			ID:                 i,
			Peers:              []int{0, 1, 2},
			ElectionTimeoutMin: 150 * time.Millisecond,
			ElectionTimeoutMax: 300 * time.Millisecond,
			HeartbeatInterval:  50 * time.Millisecond,
			Logger:             &testLogger{t: t},
		}

		transport := &debugTransport{
			id:       i,
			registry: registry,
			logger:   &testLogger{t: t},
		}

		stateMachine := &testStateMachine{
			mu:   sync.Mutex{},
			data: make(map[string]string),
		}

		node, err := NewNode(config, transport, nil, stateMachine)
		if err != nil {
			t.Fatalf("Failed to create node %d: %v", i, err)
		}

		nodes[i] = node
		registry.nodes[i] = node.(RPCHandler)
	}

	// Start all nodes
	ctx := context.Background()
	for i, node := range nodes {
		if err := node.Start(ctx); err != nil {
			t.Fatalf("Failed to start node %d: %v", i, err)
		}
		defer node.Stop()
	}

	// Wait for leader election
	time.Sleep(500 * time.Millisecond)

	// Find leader
	var leader Node
	for _, node := range nodes {
		if node.IsLeader() {
			leader = node
			break
		}
	}

	if leader == nil {
		t.Fatal("No leader elected")
	}

	// Submit some commands
	for i := 0; i < 4; i++ {
		cmd := fmt.Sprintf("cmd-%d", i)
		_, _, isLeader := leader.Submit(cmd)
		if !isLeader {
			t.Fatal("Lost leadership")
		}
	}

	// Start config change
	configChangeDone := make(chan error, 1)
	go func() {
		err := leader.AddServer(3, "server-3:8003", true)
		configChangeDone <- err
	}()

	// Submit more commands to trigger snapshot during config change
	for i := 4; i < 10; i++ {
		cmd := fmt.Sprintf("cmd-%d", i)
		_, _, isLeader := leader.Submit(cmd)
		if !isLeader {
			t.Fatal("Lost leadership during snapshot")
		}
		time.Sleep(50 * time.Millisecond)
	}

	// Wait for config change to complete
	select {
	case err := <-configChangeDone:
		if err != nil {
			t.Logf("Config change completed with: %v", err)
		}
	case <-time.After(2 * time.Second):
		t.Log("Config change timed out")
	}

	// Verify system is still functional
	_, _, isLeader := leader.Submit("post-snapshot-command")
	if !isLeader {
		t.Error("Lost leadership after snapshot during config change")
	}

	// Log that snapshot testing would be done here with proper snapshot manager
	t.Log("Snapshot functionality during config change would be tested here")
}

// TestStaleConfigEntriesAfterPartition tests handling of stale config entries after partition
func TestStaleConfigEntriesAfterPartition(t *testing.T) {
	// Create 5-node cluster with partitionable transport
	numNodes := 5
	nodes := make([]Node, numNodes)
	transports := make([]*partitionableTransport, numNodes)
	registry := &partitionRegistry{
		nodes: make(map[int]RPCHandler),
		mu:    sync.RWMutex{},
	}

	for i := 0; i < numNodes; i++ {
		config := &Config{
			ID:                 i,
			Peers:              []int{0, 1, 2, 3, 4},
			ElectionTimeoutMin: 150 * time.Millisecond,
			ElectionTimeoutMax: 300 * time.Millisecond,
			HeartbeatInterval:  50 * time.Millisecond,
		}

		transport := &partitionableTransport{
			id:       i,
			registry: registry,
			blocked:  make(map[int]bool),
		}
		transports[i] = transport

		stateMachine := &testStateMachine{
			mu:   sync.Mutex{},
			data: make(map[string]string),
		}

		node, err := NewNode(config, transport, nil, stateMachine)
		if err != nil {
			t.Fatalf("Failed to create node %d: %v", i, err)
		}

		nodes[i] = node
		registry.nodes[i] = node.(RPCHandler)
	}

	// Start all nodes
	ctx := context.Background()
	for i, node := range nodes {
		if err := node.Start(ctx); err != nil {
			t.Fatalf("Failed to start node %d: %v", i, err)
		}
		defer node.Stop()
	}

	// Wait for leader election
	time.Sleep(500 * time.Millisecond)

	// Find leader
	var leaderID int
	for i, node := range nodes {
		if node.IsLeader() {
			leaderID = i
			break
		}
	}

	t.Logf("Initial leader is node %d", leaderID)

	// Partition leader with one follower from rest
	minorityNodes := []int{leaderID, (leaderID + 1) % numNodes}
	majorityNodes := []int{}
	for i := 0; i < numNodes; i++ {
		isMinority := false
		for _, m := range minorityNodes {
			if i == m {
				isMinority = true
				break
			}
		}
		if !isMinority {
			majorityNodes = append(majorityNodes, i)
		}
	}

	// Create partition
	for _, minority := range minorityNodes {
		for _, majority := range majorityNodes {
			transports[minority].Block(majority)
			transports[majority].Block(minority)
		}
	}

	t.Logf("Partitioned: minority %v | majority %v", minorityNodes, majorityNodes)

	// Old leader tries to add server (will create uncommitted entry)
	oldLeader := nodes[leaderID]
	go func() {
		err := oldLeader.AddServer(5, "server-5:8005", true)
		t.Logf("Old leader config change result: %v", err)
	}()

	// Majority elects new leader and makes different config change
	time.Sleep(1 * time.Second)

	var newLeaderID int
	for _, i := range majorityNodes {
		if nodes[i].IsLeader() {
			newLeaderID = i
			break
		}
	}

	if nodes[newLeaderID].IsLeader() {
		t.Logf("New leader in majority: node %d", newLeaderID)

		// New leader makes different config change
		err := nodes[newLeaderID].AddServer(6, "server-6:8006", true)
		if err != nil {
			t.Logf("New leader config change: %v", err)
		}
	}

	// Heal partition
	for i := 0; i < numNodes; i++ {
		for j := 0; j < numNodes; j++ {
			transports[i].Unblock(j)
		}
	}

	t.Log("Partition healed")

	// Wait for convergence
	time.Sleep(2 * time.Second)

	// Verify all nodes have same configuration
	configs := make([]*ClusterConfiguration, numNodes)
	for i, node := range nodes {
		configs[i] = node.GetConfiguration()
		t.Logf("Node %d config: %d servers", i, len(configs[i].Servers))
	}

	// All should have same config
	referenceConfig := configs[0]
	for i := 1; i < numNodes; i++ {
		if len(configs[i].Servers) != len(referenceConfig.Servers) {
			t.Errorf("Node %d has different config size: %d vs %d",
				i, len(configs[i].Servers), len(referenceConfig.Servers))
		}
	}
}

// TestRapidLeadershipChanges tests system stability with rapid leader changes
func TestRapidLeadershipChanges(t *testing.T) {
	// Create 5-node cluster
	numNodes := 5
	nodes := make([]Node, numNodes)
	registry := &debugNodeRegistry{
		nodes:  make(map[int]RPCHandler),
		logger: &testLogger{t: t},
	}

	for i := 0; i < numNodes; i++ {
		config := &Config{
			ID:                 i,
			Peers:              []int{0, 1, 2, 3, 4},
			ElectionTimeoutMin: 100 * time.Millisecond, // Shorter timeouts
			ElectionTimeoutMax: 200 * time.Millisecond,
			HeartbeatInterval:  25 * time.Millisecond,
			Logger:             &testLogger{t: t},
		}

		transport := &debugTransport{
			id:       i,
			registry: registry,
			logger:   &testLogger{t: t},
		}

		stateMachine := &testStateMachine{
			mu:   sync.Mutex{},
			data: make(map[string]string),
		}

		node, err := NewNode(config, transport, nil, stateMachine)
		if err != nil {
			t.Fatalf("Failed to create node %d: %v", i, err)
		}

		nodes[i] = node
		registry.nodes[i] = node.(RPCHandler)
	}

	// Start all nodes
	ctx := context.Background()
	for i, node := range nodes {
		if err := node.Start(ctx); err != nil {
			t.Fatalf("Failed to start node %d: %v", i, err)
		}
	}

	// Track leader changes
	leaderChanges := 0
	lastLeader := -1

	// Force rapid leader changes by stopping leaders
	for round := 0; round < 5; round++ {
		// Wait for leader election
		time.Sleep(300 * time.Millisecond)

		// Find and stop current leader
		for i, node := range nodes {
			if node.IsLeader() {
				if i != lastLeader {
					leaderChanges++
					lastLeader = i
				}

				t.Logf("Round %d: Stopping leader node %d", round, i)
				node.Stop()
				break
			}
		}
	}

	// Restart all stopped nodes
	for i, node := range nodes {
		n := node.(*raftNode)
		select {
		case <-n.stopCh:
			// Node is stopped, restart it
			newNode, err := NewNode(&Config{
				ID:                 i,
				Peers:              []int{0, 1, 2, 3, 4},
				ElectionTimeoutMin: 100 * time.Millisecond,
				ElectionTimeoutMax: 200 * time.Millisecond,
				HeartbeatInterval:  25 * time.Millisecond,
				Logger:             &testLogger{t: t},
			}, &debugTransport{
				id:       i,
				registry: registry,
				logger:   &testLogger{t: t},
			}, nil, &testStateMachine{
				mu:   sync.Mutex{},
				data: make(map[string]string),
			})

			if err != nil {
				t.Fatalf("Failed to restart node %d: %v", i, err)
			}

			nodes[i] = newNode
			registry.nodes[i] = newNode.(RPCHandler)

			if err := newNode.Start(ctx); err != nil {
				t.Fatalf("Failed to start node %d: %v", i, err)
			}

			t.Logf("Restarted node %d", i)
		default:
			// Node is running
		}
	}

	// Wait for stabilization
	time.Sleep(1 * time.Second)

	// Verify system stabilized with one leader
	leaderCount := 0
	for i, node := range nodes {
		if node.IsLeader() {
			leaderCount++
			t.Logf("Final leader: node %d", i)
		}
	}

	if leaderCount != 1 {
		t.Errorf("Expected exactly 1 leader after stabilization, found %d", leaderCount)
	}

	t.Logf("System experienced %d leader changes", leaderChanges)

	// Clean up
	for _, node := range nodes {
		node.Stop()
	}
}

// TestAsymmetricPartitionVariants tests different asymmetric partition scenarios
func TestAsymmetricPartitionVariants(t *testing.T) {
	// Create 5-node cluster with asymmetric transport
	numNodes := 5
	nodes := make([]Node, numNodes)
	transports := make([]*asymmetricTransport, numNodes)
	registry := &asymmetricRegistry{
		nodes: make(map[int]RPCHandler),
		mu:    sync.RWMutex{},
	}

	for i := 0; i < numNodes; i++ {
		config := &Config{
			ID:                 i,
			Peers:              []int{0, 1, 2, 3, 4},
			ElectionTimeoutMin: 150 * time.Millisecond,
			ElectionTimeoutMax: 300 * time.Millisecond,
			HeartbeatInterval:  50 * time.Millisecond,
		}

		transport := &asymmetricTransport{
			id:              i,
			registry:        registry,
			blockedIncoming: make(map[int]bool),
			blockedOutgoing: make(map[int]bool),
		}
		transports[i] = transport

		stateMachine := &testStateMachine{
			mu:   sync.Mutex{},
			data: make(map[string]string),
		}

		node, err := NewNode(config, transport, nil, stateMachine)
		if err != nil {
			t.Fatalf("Failed to create node %d: %v", i, err)
		}

		nodes[i] = node
		registry.nodes[i] = node.(RPCHandler)
	}

	// Start all nodes
	ctx := context.Background()
	for i, node := range nodes {
		if err := node.Start(ctx); err != nil {
			t.Fatalf("Failed to start node %d: %v", i, err)
		}
		defer node.Stop()
	}

	// Test 1: Leader can send but not receive
	t.Log("Test 1: Leader can send but cannot receive responses")

	// Wait for initial leader
	time.Sleep(500 * time.Millisecond)

	var leaderID int
	for i, node := range nodes {
		if node.IsLeader() {
			leaderID = i
			break
		}
	}

	t.Logf("Initial leader: node %d", leaderID)

	// Block incoming to leader
	for i := 0; i < numNodes; i++ {
		if i != leaderID {
			transports[leaderID].BlockIncomingFrom(i)
		}
	}

	// Leader should step down eventually (no successful heartbeats)
	time.Sleep(1 * time.Second)

	if nodes[leaderID].IsLeader() {
		t.Error("Leader should step down when it cannot receive responses")
	}

	// Clear blocks
	for i := 0; i < numNodes; i++ {
		transports[i].UnblockIncomingFrom(leaderID)
	}

	// Test 2: Follower can receive but not send
	t.Log("Test 2: Follower can receive but cannot send")

	time.Sleep(500 * time.Millisecond)

	// Find new leader and a follower
	var newLeaderID int
	var followerID int
	for i, node := range nodes {
		if node.IsLeader() {
			newLeaderID = i
		} else {
			followerID = i
		}
	}

	t.Logf("Leader: node %d, testing follower: node %d", newLeaderID, followerID)

	// Block outgoing from follower
	for i := 0; i < numNodes; i++ {
		if i != followerID {
			transports[followerID].BlockOutgoingTo(i)
		}
	}

	// Follower should still receive heartbeats and not start election
	initialTerm := nodes[followerID].GetCurrentTerm()
	time.Sleep(500 * time.Millisecond)

	newTerm := nodes[followerID].GetCurrentTerm()
	if newTerm > initialTerm+1 {
		t.Error("Follower started unnecessary elections despite receiving heartbeats")
	}

	// Test 3: Complex asymmetric scenario
	t.Log("Test 3: Complex asymmetric partition")

	// Clear all blocks
	for i := 0; i < numNodes; i++ {
		for j := 0; j < numNodes; j++ {
			transports[i].UnblockIncomingFrom(j)
			transports[i].UnblockOutgoingTo(j)
		}
	}

	// Create ring partition: each node can only send to next node
	for i := 0; i < numNodes; i++ {
		for j := 0; j < numNodes; j++ {
			if j != (i+1)%numNodes {
				transports[i].BlockOutgoingTo(j)
			}
		}
	}

	t.Log("Created ring partition: each node can only send to next")

	// System should not be able to elect leader (no bidirectional communication)
	time.Sleep(1 * time.Second)

	leaderCount := 0
	for _, node := range nodes {
		if node.IsLeader() {
			leaderCount++
		}
	}

	if leaderCount > 0 {
		t.Errorf("Should have no leader in ring partition, found %d", leaderCount)
	}
}

// TestConfigChangeTimeoutRecovery tests recovery from config change timeouts
func TestConfigChangeTimeoutRecovery(t *testing.T) {
	// Create 3-node cluster
	nodes := make([]Node, 3)
	transports := make([]*slowTransport, 3)
	registry := &slowRegistry{
		nodes: make(map[int]RPCHandler),
		mu:    sync.RWMutex{},
	}

	for i := 0; i < 3; i++ {
		config := &Config{
			ID:                 i,
			Peers:              []int{0, 1, 2},
			ElectionTimeoutMin: 150 * time.Millisecond,
			ElectionTimeoutMax: 300 * time.Millisecond,
			HeartbeatInterval:  50 * time.Millisecond,
			Logger:             &testLogger{t: t},
		}

		transport := &slowTransport{
			id:       i,
			registry: registry,
			delay:    0, // Start with no delay
			logger:   &testLogger{t: t},
		}
		transports[i] = transport

		stateMachine := &testStateMachine{
			mu:   sync.Mutex{},
			data: make(map[string]string),
		}

		node, err := NewNode(config, transport, nil, stateMachine)
		if err != nil {
			t.Fatalf("Failed to create node %d: %v", i, err)
		}

		nodes[i] = node
		registry.nodes[i] = node.(RPCHandler)
	}

	// Start all nodes
	ctx := context.Background()
	for i, node := range nodes {
		if err := node.Start(ctx); err != nil {
			t.Fatalf("Failed to start node %d: %v", i, err)
		}
		defer node.Stop()
	}

	// Wait for leader election
	time.Sleep(500 * time.Millisecond)

	// Find leader
	var leader Node
	for _, node := range nodes {
		if node.IsLeader() {
			leader = node
			break
		}
	}

	if leader == nil {
		t.Fatal("No leader elected")
	}

	// Add extreme delay to simulate timeout scenario
	for _, transport := range transports {
		transport.setDelay(2 * time.Second)
	}

	// Try config change (will likely timeout)
	configDone := make(chan error, 1)
	go func() {
		err := leader.AddServer(3, "server-3:8003", true)
		configDone <- err
	}()

	// Wait a bit then reduce delay
	time.Sleep(500 * time.Millisecond)
	for _, transport := range transports {
		transport.setDelay(10 * time.Millisecond)
	}

	// Wait for config change result
	select {
	case err := <-configDone:
		t.Logf("Config change completed: %v", err)
	case <-time.After(3 * time.Second):
		t.Log("Config change timed out")
	}

	// Verify system is still functional
	_, _, isLeader := leader.Submit("recovery-test")
	if !isLeader {
		// Find new leader
		for _, node := range nodes {
			if node.IsLeader() {
				leader = node
				break
			}
		}
	}

	// System should recover and be able to process commands
	index, _, isLeader := leader.Submit("post-recovery-command")
	if !isLeader {
		t.Error("No leader after config timeout recovery")
	} else {
		t.Logf("System recovered, command accepted at index %d", index)
	}
}

// slowTransport simulates slow network
type slowTransport struct {
	id       int
	registry *slowRegistry
	handler  RPCHandler
	delay    time.Duration
	mu       sync.RWMutex
	logger   Logger
}

type slowRegistry struct {
	mu    sync.RWMutex
	nodes map[int]RPCHandler
}

func (t *slowTransport) setDelay(d time.Duration) {
	t.mu.Lock()
	defer t.mu.Unlock()
	t.delay = d
}

func (t *slowTransport) getDelay() time.Duration {
	t.mu.RLock()
	defer t.mu.RUnlock()
	return t.delay
}

func (t *slowTransport) SendRequestVote(serverID int, args *RequestVoteArgs) (*RequestVoteReply, error) {
	delay := t.getDelay()
	if delay > 0 {
		time.Sleep(delay)
	}

	t.registry.mu.RLock()
	handler, exists := t.registry.nodes[serverID]
	t.registry.mu.RUnlock()

	if !exists {
		return nil, fmt.Errorf("server %d not found", serverID)
	}

	reply := &RequestVoteReply{}
	err := handler.RequestVote(args, reply)
	return reply, err
}

func (t *slowTransport) SendAppendEntries(serverID int, args *AppendEntriesArgs) (*AppendEntriesReply, error) {
	delay := t.getDelay()
	if delay > 0 {
		time.Sleep(delay)
	}

	t.registry.mu.RLock()
	handler, exists := t.registry.nodes[serverID]
	t.registry.mu.RUnlock()

	if !exists {
		return nil, fmt.Errorf("server %d not found", serverID)
	}

	reply := &AppendEntriesReply{}
	err := handler.AppendEntries(args, reply)
	return reply, err
}

func (t *slowTransport) SendInstallSnapshot(serverID int, args *InstallSnapshotArgs) (*InstallSnapshotReply, error) {
	delay := t.getDelay()
	if delay > 0 {
		time.Sleep(delay)
	}

	t.registry.mu.RLock()
	handler, exists := t.registry.nodes[serverID]
	t.registry.mu.RUnlock()

	if !exists {
		return nil, fmt.Errorf("server %d not found", serverID)
	}

	reply := &InstallSnapshotReply{}
	err := handler.InstallSnapshot(args, reply)
	return reply, err
}

func (t *slowTransport) SetRPCHandler(handler RPCHandler) {
	t.handler = handler
}

func (t *slowTransport) Start() error {
	return nil
}

func (t *slowTransport) Stop() error {
	return nil
}

func (t *slowTransport) GetAddress() string {
	return fmt.Sprintf("slow-transport-%d", t.id)
}
